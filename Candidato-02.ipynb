{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 3 Semana 11  \n",
    "Nombres: \n",
    "- Xavier Fuentes\n",
    "- Víctor Hernández\n",
    "- Rodrigo Gallardo\n",
    "- Sebastián Lantadilla\n",
    "- Iván Rojas\n",
    "\n",
    "NCR: 2107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 21:23:20.987811: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-20 21:23:20.991443: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-20 21:23:21.005627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734740601.026975   28149 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734740601.032731   28149 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 21:23:21.054499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Se importan las librerías necesarias.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_excel('fraudes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 971 entries, 0 to 970\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      971 non-null    float64\n",
      " 1   V2      971 non-null    float64\n",
      " 2   V3      971 non-null    float64\n",
      " 3   V4      971 non-null    float64\n",
      " 4   V5      971 non-null    float64\n",
      " 5   V6      971 non-null    float64\n",
      " 6   V7      971 non-null    float64\n",
      " 7   V8      971 non-null    float64\n",
      " 8   V9      971 non-null    float64\n",
      " 9   V10     971 non-null    float64\n",
      " 10  V11     971 non-null    float64\n",
      " 11  V12     971 non-null    float64\n",
      " 12  V13     971 non-null    float64\n",
      " 13  V14     971 non-null    float64\n",
      " 14  V15     971 non-null    float64\n",
      " 15  V16     971 non-null    float64\n",
      " 16  V17     971 non-null    float64\n",
      " 17  V18     971 non-null    float64\n",
      " 18  V19     971 non-null    float64\n",
      " 19  V20     971 non-null    float64\n",
      " 20  V21     971 non-null    float64\n",
      " 21  V22     971 non-null    float64\n",
      " 22  V23     971 non-null    float64\n",
      " 23  V24     971 non-null    float64\n",
      " 24  V25     971 non-null    float64\n",
      " 25  V26     971 non-null    float64\n",
      " 26  V27     971 non-null    float64\n",
      " 27  V28     971 non-null    float64\n",
      " 28  Amount  971 non-null    float64\n",
      " 29  Class   971 non-null    int64  \n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 227.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Se visualiza la estructura y si hay datos nulos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploración de datos y limpieza\n",
    "# Se chequean si hay nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separan las variables \n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se justan las variables (columnas) del conjunto de datos X para que todas tengan una escala similar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se prepara un conjunto de datos para el entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de regresión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        93\n",
      "           1       1.00      0.95      0.97       102\n",
      "\n",
      "    accuracy                           0.97       195\n",
      "   macro avg       0.97      0.98      0.97       195\n",
      "weighted avg       0.98      0.97      0.97       195\n",
      "\n",
      "Precisión: 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "## Modelo de Regresión Logística\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(\"Modelo de regresión:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"Precisión: {logreg_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        93\n",
      "           1       1.00      0.97      0.99       102\n",
      "\n",
      "    accuracy                           0.98       195\n",
      "   macro avg       0.98      0.99      0.98       195\n",
      "weighted avg       0.99      0.98      0.98       195\n",
      "\n",
      "Precisión: 0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "## Modelo Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Modelo Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Precisión: {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        93\n",
      "           1       1.00      0.94      0.97       102\n",
      "\n",
      "    accuracy                           0.97       195\n",
      "   macro avg       0.97      0.97      0.97       195\n",
      "weighted avg       0.97      0.97      0.97       195\n",
      "\n",
      "Precisión: 0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "## Modelo SVM Support Vector Machine\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "print(\"Modelo Support Vector Machine:\")\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "svc_accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "print(f\"Precisión: {svc_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xcx/leng/py/envpy/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-12-20 21:23:24.265984: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "## Modelo de redes neuronales\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7849 - loss: 0.5725\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3324 \n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2522 \n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2108 \n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.1729 \n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1387 \n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1204 \n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.1244 \n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1224 \n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1258 \n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1085 \n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1104 \n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1078 \n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1035 \n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0985 \n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0827 \n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0926 \n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.0924 \n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.0902 \n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.0870 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Modelo de redes neuronales:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        93\n",
      "           1       0.98      0.95      0.97       102\n",
      "\n",
      "    accuracy                           0.96       195\n",
      "   macro avg       0.96      0.96      0.96       195\n",
      "weighted avg       0.96      0.96      0.96       195\n",
      "\n",
      "Precisión: 0.9641025641025641\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "y_pred_nn = (model.predict(X_test) > 0.5).astype('int32')\n",
    "print(\"Modelo de redes neuronales:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Precisión: {nn_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regresión logística: 0.9748743718592965, Precisión: 0.9743589743589743\n",
      "Modelo Random Forest:          0.9850746268656716, Precisión: 0.9846153846153847\n",
      "Modelo SVM:                    0.9696969696969697, Precisión: 0.9692307692307692\n",
      "Modelo de redes neuronales:    0.9651741293532339, Precisión: 0.9641025641025641\n"
     ]
    }
   ],
   "source": [
    "## Comparación de modelos\n",
    "\n",
    "# Se recopilan puntajes F1 y precisión para la comparación\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "f1_nn = f1_score(y_test, y_pred_nn)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "svc_accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "\n",
    "# Se imprimen \n",
    "print(f\"Modelo de Regresión logística: {f1_logreg:.16f}, Precisión: {logreg_accuracy}\")\n",
    "print(f\"Modelo Random Forest: {f1_rf:>27.16f}, Precisión: {rf_accuracy}\")\n",
    "print(f\"Modelo SVM: {f1_svc:>37.16f}, Precisión: {svc_accuracy}\")\n",
    "print(f\"Modelo de redes neuronales: {f1_nn:>21.16f}, Precisión: {nn_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo es: Random Forest, con una precisión de: 0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "# Determinación del mejor modelo\n",
    "\n",
    "best_model = max([(f1_logreg, logreg_accuracy, 'Regresión Logística'),\n",
    "                  (f1_rf, rf_accuracy, 'Random Forest'),\n",
    "                  (f1_svc, svc_accuracy, 'Support Vector Machine'),\n",
    "                  (f1_nn, nn_accuracy, 'Red Neuronal')], key=lambda x: x[0])\n",
    "\n",
    "print(f\"El mejor modelo es: {best_model[2]}, con una precisión de: {best_model[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo siguiente es para simular tener un csv sin la columna Class\n",
    "df_reducido = df.drop(columns=['Class'])\n",
    "\n",
    "# Si se quisiera guardar el csv sin la columna class\n",
    "# df_reducido.to_csv('dataset_sin_class.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica un escalado estándar a los datos contenidos en el DataFrame reducido\n",
    "df_reducido_scaled = scaler.transform(df_reducido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica el modelo a cada fila y crea una nueva columna denominada resultado con el resultado\n",
    "\n",
    "predicciones = rf.predict(df_reducido_scaled)\n",
    "df_reducido['resultados'] = predicciones\n",
    "\n",
    "# Guarda en un archivo csv denominado resultado.csv\n",
    "df_reducido.to_csv('resultados.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
